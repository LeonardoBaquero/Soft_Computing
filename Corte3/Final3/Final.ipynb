{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13a61a7d",
   "metadata": {},
   "source": [
    "Crear canva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8900947a-f05c-427c-a008-c4bca105c439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\leona\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: ipycanvas in c:\\users\\leona\\anaconda3\\lib\\site-packages (0.13.3)\n",
      "Requirement already satisfied: ipywidgets<9,>=7.6.0 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from ipycanvas) (8.1.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\leona\\anaconda3\\lib\\site-packages (from ipycanvas) (1.26.4)\n",
      "Requirement already satisfied: pillow>=6.0 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from ipycanvas) (10.3.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from ipywidgets<9,>=7.6.0->ipycanvas) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from ipywidgets<9,>=7.6.0->ipycanvas) (8.25.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from ipywidgets<9,>=7.6.0->ipycanvas) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from ipywidgets<9,>=7.6.0->ipycanvas) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from ipywidgets<9,>=7.6.0->ipycanvas) (3.0.13)\n",
      "Requirement already satisfied: decorator in c:\\users\\leona\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipycanvas) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipycanvas) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\leona\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipycanvas) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipycanvas) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipycanvas) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\leona\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipycanvas) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\leona\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipycanvas) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipycanvas) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\leona\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipycanvas) (0.2.5)\n",
      "Requirement already satisfied: executing in c:\\users\\leona\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipycanvas) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\leona\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipycanvas) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\leona\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipycanvas) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\users\\leona\\anaconda3\\lib\\site-packages (from asttokens->stack-data->ipython>=6.1.0->ipywidgets<9,>=7.6.0->ipycanvas) (1.16.0)\n",
      "Requirement already satisfied: jupyterlab_widgets in c:\\users\\leona\\anaconda3\\lib\\site-packages (3.0.13)\n",
      "Requirement already satisfied: torchvision in c:\\users\\leona\\anaconda3\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.5.1 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torchvision) (2.5.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from jinja2->torch==2.5.1->torchvision) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install torch\n",
    "!pip install ipycanvas\n",
    "!pip install jupyterlab_widgets\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0807c95-ee57-4854-aac1-c72ad4c6b225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "686b090f-9205-4053-ade8-6916d9a6a6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55b1d2b1718497e8a385f1b9a757647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=200, sync_image_data=True, width=200)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Esta celda realiza las siguientes operaciones:\n",
    "# - Configura un lienzo interactivo para dibujar formas.\n",
    "# - Implementa funciones para capturar dibujos y procesarlos.\n",
    "\n",
    "from ipycanvas import Canvas # Proporciona la funcionalidad para crear lienzos interactivos en Jupyter Notebook.\n",
    "from PIL import Image, ImageDraw # Se utiliza para trabajar con imágenes, como convertir de matrices a imágenes y viceversa.\n",
    "import numpy as np # Es esencial para realizar operaciones matemáticas en arreglos (como las imágenes que se representan como matrices).\n",
    "import os # Permite interactuar con el sistema operativo, como crear directorios.\n",
    "\n",
    "# Se crea un lienzo blanco de 200x200 píxeles.\n",
    "canvas = Canvas(width=200, height=200, background_color=\"white\", sync_image_data = True)\n",
    "# La opción sync_image_data = True asegura que los cambios en el lienzo se reflejen en la representación de la imagen.\n",
    "\n",
    "# Función para capturar el dibujo como imagen\n",
    "def get_drawing(): # Obtiene los datos de la imagen del lienzo.\n",
    "    # Convierte la imagen del lienzo a una matriz NumPy y luego a imagen de escala de grises    \n",
    "    img = Image.fromarray(canvas.get_image_data(0, 0, 200, 200))\n",
    "    # Convertir la imagen a escala de grises (L)\n",
    "    img = img.convert(\"L\")\n",
    "    img = img.resize((28, 28))  # Redimensionar a 28x28 píxeles\n",
    "    # Convertir la imagen en escala de grises a una matriz NumPy\n",
    "    return np.array(img)\n",
    "\n",
    "# Función para guardar el dibujo\n",
    "def save_drawing(class_name, count): # Crea un directorio para almacenar las imágenes de la clase especificada (por ejemplo, \"0\", \"1\", \"2\" para dígitos).\n",
    "    # Crear directorio si no existe\n",
    "    os.makedirs(f\"data/{class_name}\", exist_ok=True) # exist_ok=True evita errores si el directorio ya existe.\n",
    "    # Obtiene el dibujo del lienzo utilizando get_drawing().\n",
    "    img = get_drawing()\n",
    "    \n",
    "    # Guardar la imagen en el directorio especificado\n",
    "    filepath = f\"data/{class_name}/{count}.png\"\n",
    "    Image.fromarray(img).save(filepath)\n",
    "    print(f\"Dibujo guardado en: {filepath}\")\n",
    "\n",
    "\n",
    "# Variable para almacenar la última posición\n",
    "last_x, last_y = None, None\n",
    "\n",
    "# Función para dibujar en el lienzo\n",
    "def on_mouse_down(x, y): \n",
    "    global last_x, last_y\n",
    "    canvas.fill_style = \"black\"\n",
    "    last_x, last_y = x, y  # Guardar la posición inicial cuando se presiona el botón del mouse\n",
    "\n",
    "def on_mouse_move(x, y): # Se definen funciones para manejar los eventos de clic, movimiento y liberación del mouse.\n",
    "    global last_x, last_y\n",
    "    if last_x is not None and last_y is not None:\n",
    "        canvas.stroke_style = \"black\"\n",
    "        canvas.line_width = 5\n",
    "        canvas.begin_path()\n",
    "        canvas.move_to(last_x, last_y)\n",
    "        canvas.line_to(x, y)\n",
    "        canvas.stroke()\n",
    "        last_x, last_y = x, y  # Actualizar la posición de la última coordenada\n",
    "\n",
    "def on_mouse_up(x, y):\n",
    "    global last_x, last_y\n",
    "    last_x, last_y = None, None  # Resetear cuando se suelta el mouse\n",
    "\n",
    "# Asignar los eventos de mouse al lienzo\n",
    "canvas.on_mouse_down(on_mouse_down)\n",
    "canvas.on_mouse_move(on_mouse_move)\n",
    "canvas.on_mouse_up(on_mouse_up)\n",
    "\n",
    "# Mostrar el lienzo\n",
    "display(canvas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63ff3f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dibujo guardado en: data/square/7.png\n"
     ]
    }
   ],
   "source": [
    "# Se guarda imagen en un directorio específico.\n",
    "save_drawing(\"square\", 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ccbae4",
   "metadata": {},
   "source": [
    "Generar Imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3bff446b-b360-4b75-b0f1-9b76ea760c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta celda realiza las siguientes operaciones:\n",
    "# - Genera datos sintéticos de varias formas geométricas (círculos, cuadrados, etc.).\n",
    "# - Guarda estas imágenes en una estructura de carpetas.\n",
    "\n",
    "# Generar formas sintéticas\n",
    "\n",
    "def generate_synthetic_data(class_name, count): # Esta función genera y guarda imágenes de formas geométricas básicas en blanco y negro.\n",
    "    os.makedirs(f\"data/{class_name}\", exist_ok=True)\n",
    "    for i in range(count):\n",
    "        # Crear una imagen en blanco\n",
    "        img = Image.new(\"L\", (28, 28), \"white\") # Imagen de  28X28 píxeles en escala de grises \"L\"\n",
    "        draw = ImageDraw.Draw(img) # Crea un objeto ImageDraw.Draw para dibujar en la imagen.\n",
    "\n",
    "        # Nombre de la clase de la forma geométrica a generar. Debe ser \"circle\", \"square\", \"triangle\" o \"star\"\n",
    "        if class_name == \"circle\":\n",
    "            draw.ellipse((5, 5, 23, 23), outline=\"black\", fill=\"black\")\n",
    "        elif class_name == \"square\":\n",
    "            draw.rectangle((5, 5, 23, 23), outline=\"black\", fill=\"black\")\n",
    "        elif class_name == \"triangle\":\n",
    "            draw.polygon([(14, 5), (5, 23), (23, 23)], outline=\"black\", fill=\"black\")\n",
    "        elif class_name == \"star\":\n",
    "            draw.polygon([(14, 5), (10, 20), (5, 14), (23, 14), (18, 20)], outline=\"black\", fill=\"black\")\n",
    "\n",
    "        # Guardar la imagen\n",
    "        filepath = f\"data/{class_name}/{i}.png\" # Ruta del archivo \n",
    "        img.save(filepath) # Acá se guarda la imagen en la ruta \n",
    "        #print(f\"Dibujo sintético guardado en: {filepath}\")\n",
    "\n",
    "# Generar 100 imágenes sintéticas por clase\n",
    "generate_synthetic_data(\"circle\", 100)\n",
    "generate_synthetic_data(\"square\", 100)\n",
    "generate_synthetic_data(\"triangle\", 100)\n",
    "generate_synthetic_data(\"star\", 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db075717",
   "metadata": {},
   "source": [
    "Cargar imágenes en el Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7ba2876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta celda realiza las siguientes operaciones:\n",
    "# - Define una clase personalizada para cargar imágenes en un dataset.\n",
    "# - Aplica transformaciones como normalización y conversión a tensor.\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "class DrawingDataset(Dataset): # root_dir es la ruta del directorio raíz que contiene las imágenes del dataset.\n",
    "    def __init__(self, root_dir, transform=None): # Metodo que inicializa el dataset, verifica exisitencia de la imagen \n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform # Del objeto de transforms de torchvision para transformaciones que se aplicarán a las imágenes cargadas.\n",
    "        self.filepaths = glob.glob(os.path.join(root_dir, \"*\", \"*.png\")) # Lista de rutas de las imágenes en el dataset\n",
    "\n",
    "        if not self.filepaths:\n",
    "            raise ValueError(f\"No se encontraron imágenes en {root_dir}. Verifica la estructura del directorio.\")\n",
    "            \n",
    "        # Lista de etiquetas correspondientes a cada imagen, basadas en el nombre del directorio padre\n",
    "        self.labels = [os.path.basename(os.path.dirname(path)) for path in self.filepaths]\n",
    "        # Diccionario que mapea cada etiqueta única a un índice entero.\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(set(self.labels))}\n",
    "\n",
    "    # Devuelve el tamaño del dataset (número total de imágenes).\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "\n",
    "    # Obtiene una imagen y su etiqueta correspondiente a un índice específico\n",
    "    def __getitem__(self, idx):\n",
    "            # Abrir imagen y convertirla a escala de grises\n",
    "            img = Image.open(self.filepaths[idx]).convert(\"L\")  # Convertir a escala de grises (1 canal)\n",
    "            label = self.label_to_idx[self.labels[idx]] # Obtiene la etiqueta del diccionario\n",
    "            \n",
    "            # Aplicar transformaciones\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            else:\n",
    "                # Si no hay transformaciones, convierte la imagen a un tensor usando\n",
    "                img = transforms.ToTensor()(img)\n",
    "            \n",
    "            return img, label # Devuelve una tupla con la imagen (como tensor) y su etiqueta (como entero).\n",
    "# Transformaciones para normalizar imágenes\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),       # Asegurar tamaño 28x28\n",
    "    transforms.ToTensor(),            # Convertir a tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalizar\n",
    "])\n",
    "\n",
    "# Cargar el dataset\n",
    "dataset = DrawingDataset(root_dir=\"data\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f0293",
   "metadata": {},
   "source": [
    "Paso 3: Crear y Entrenar el Modelo CNN Definimos un modelo básico en PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0f0a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la clase ImprovedCNN, que hereda de nn.Module para construir una red neuronal personalizada\n",
    "class ImprovedCNN(nn.Module):  \n",
    "    # Método constructor para inicializar los componentes de la red\n",
    "    def __init__(self, num_classes):  \n",
    "        # Llama al constructor de la clase base nn.Module\n",
    "        super(ImprovedCNN, self).__init__()  \n",
    "        # Primera capa convolucional con 1 canal de entrada, 32 filtros, tamaño de kernel 3x3, y padding de 1\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  \n",
    "        # Normalización por lotes para los 32 mapas de características de la primera capa convolucional\n",
    "        self.bn1 = nn.BatchNorm2d(32)  \n",
    "        # Segunda capa convolucional con 32 canales de entrada, 64 filtros, y configuración similar\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  \n",
    "        # Normalización por lotes para los 64 mapas de características\n",
    "        self.bn2 = nn.BatchNorm2d(64)  \n",
    "        # Tercera capa convolucional con 64 canales de entrada y 128 filtros\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  \n",
    "        # Normalización por lotes para los 128 mapas de características\n",
    "        self.bn3 = nn.BatchNorm2d(128)  \n",
    "        # Capa de agrupamiento máximo con tamaño de ventana 2x2 y salto de 2\n",
    "        self.pool = nn.MaxPool2d(2, 2)  \n",
    "        # Primera capa completamente conectada, reduce a 256 neuronas (tamaño de entrada depende de la salida convolucional)\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 256)  \n",
    "        # Segunda capa completamente conectada para clasificar en el número de clases especificado\n",
    "        self.fc2 = nn.Linear(256, num_classes)  \n",
    "        # Capa Dropout para prevenir sobreajuste, desactivando el 50% de las neuronas durante el entrenamiento\n",
    "        self.dropout = nn.Dropout(0.5)  \n",
    "\n",
    "    # Método forward para definir cómo los datos pasan por las capas de la red\n",
    "    def forward(self, x):  \n",
    "        # Pasa los datos por la primera capa convolucional, BatchNorm, ReLU, y luego por MaxPooling\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  \n",
    "        # Pasa los datos por la segunda capa convolucional, BatchNorm, ReLU, y luego por MaxPooling\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  \n",
    "        # Pasa los datos por la tercera capa convolucional, BatchNorm, ReLU, y luego por MaxPooling\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))  \n",
    "        # Reorganiza los datos en una forma plana para la entrada a las capas completamente conectadas\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        # Pasa los datos por la primera capa completamente conectada y aplica la función de activación ReLU\n",
    "        x = F.relu(self.fc1(x))  \n",
    "        # Aplica Dropout para prevenir sobreajuste\n",
    "        x = self.dropout(x)  \n",
    "        # Pasa los datos por la segunda capa completamente conectada para producir la salida final\n",
    "        x = self.fc2(x)  \n",
    "        # Devuelve la salida de la red\n",
    "        return x  \n",
    "\n",
    "# Obtiene el número de clases del conjunto de datos usando su mapeo de etiquetas a índices\n",
    "num_classes = len(dataset.label_to_idx)  \n",
    "# Crea una instancia del modelo ImprovedCNN, enviándola al dispositivo adecuado (GPU si está disponible, de lo contrario CPU)\n",
    "model = ImprovedCNN(num_classes).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab358054",
   "metadata": {},
   "source": [
    "Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "874e00b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.1569, Accuracy: 93.75%\n",
      "Epoch 2/5, Loss: 0.0002, Accuracy: 100.00%\n",
      "Epoch 3/5, Loss: 0.0002, Accuracy: 100.00%\n",
      "Epoch 4/5, Loss: 0.0001, Accuracy: 100.00%\n",
      "Epoch 5/5, Loss: 0.0001, Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Define una función para entrenar el modelo, tomando como parámetros el modelo, dataloader, función de pérdida, optimizador, y el número de épocas\n",
    "def train_model(model, dataloader, criterion, optimizer, epochs=5):  \n",
    "    # Detecta si hay una GPU disponible y la usa; de lo contrario, utiliza la CPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \n",
    "    # Envía el modelo al dispositivo (GPU o CPU)\n",
    "    model.to(device)  \n",
    "    # Lista para almacenar los valores de pérdida de cada época\n",
    "    loss_values = []  \n",
    "    # Lista para almacenar la precisión de cada época\n",
    "    accuracy_values = []  \n",
    "\n",
    "    # Itera a través del número especificado de épocas\n",
    "    for epoch in range(epochs):  \n",
    "        # Cambia el modelo al modo de entrenamiento (habilita dropout y batch norm para entrenamiento)\n",
    "        model.train()  \n",
    "        # Inicializa acumuladores para la pérdida y métricas de precisión\n",
    "        running_loss = 0.0  \n",
    "        correct = 0  # Número de predicciones correctas\n",
    "        total = 0  # Número total de muestras procesadas\n",
    "\n",
    "        # Itera a través del dataloader para procesar lotes de imágenes y etiquetas\n",
    "        for images, labels in dataloader:  \n",
    "            # Envía las imágenes y etiquetas al dispositivo (GPU o CPU)\n",
    "            images, labels = images.to(device), labels.to(device)  \n",
    "\n",
    "            # Reinicia los gradientes acumulados del optimizador\n",
    "            optimizer.zero_grad()  \n",
    "            # Pasa las imágenes a través del modelo para obtener las predicciones\n",
    "            outputs = model(images)  \n",
    "            # Calcula la pérdida entre las predicciones y las etiquetas verdaderas\n",
    "            loss = criterion(outputs, labels)  \n",
    "            # Calcula los gradientes para todos los parámetros del modelo\n",
    "            loss.backward()  \n",
    "            # Actualiza los parámetros del modelo usando los gradientes calculados\n",
    "            optimizer.step()  \n",
    "\n",
    "            # Suma la pérdida del lote actual al acumulador de pérdidas\n",
    "            running_loss += loss.item()  \n",
    "            # Obtiene las predicciones de clase más probables para cada muestra\n",
    "            _, predicted = torch.max(outputs, 1)  \n",
    "            # Incrementa el conteo total de muestras procesadas\n",
    "            total += labels.size(0)  \n",
    "            # Incrementa el conteo de predicciones correctas comparándolas con las etiquetas reales\n",
    "            correct += (predicted == labels).sum().item()  \n",
    "\n",
    "        # Calcula la pérdida promedio de la época\n",
    "        epoch_loss = running_loss / len(dataloader)  \n",
    "        # Calcula la precisión promedio de la época\n",
    "        epoch_accuracy = 100 * correct / total  \n",
    "        # Almacena la pérdida promedio de la época en la lista de pérdidas\n",
    "        loss_values.append(epoch_loss)  \n",
    "        # Almacena la precisión promedio de la época en la lista de precisiones\n",
    "        accuracy_values.append(epoch_accuracy)  \n",
    "\n",
    "        # Imprime los resultados de la época actual: pérdida promedio y precisión promedio\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")  \n",
    "\n",
    "    # Devuelve las listas de pérdida y precisión para todas las épocas\n",
    "    return loss_values, accuracy_values  \n",
    "\n",
    "# Inicializa la función de pérdida como entropía cruzada para clasificación multiclase\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "# Inicializa el optimizador Adam con los parámetros del modelo y una tasa de aprendizaje de 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  \n",
    "\n",
    "# Llama a la función train_model para entrenar el modelo con el dataloader, criterio, optimizador y 5 épocas\n",
    "loss_values, accuracy_values = train_model(model, dataloader, criterion, optimizer, epochs=5)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "540e5f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55b1d2b1718497e8a385f1b9a757647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=200, image_data=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xc8\\x00\\x00\\x00\\xc8\\x08\\x06\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e5da43",
   "metadata": {},
   "source": [
    "Entrenamos el modelo con los datos capturados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "09e826ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción: square\n"
     ]
    }
   ],
   "source": [
    "# Esta celda realiza las siguientes operaciones:\n",
    "# - Utiliza un modelo previamente entrenado para predecir la clase de un dibujo en el lienzo.\n",
    "# - Limpia el lienzo después de realizar una predicción.\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Crear la transformación que se debe aplicar al dibujo\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                  # Convierte a tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))    # Normaliza (ajusta según las necesidades del modelo)\n",
    "])\n",
    "\n",
    "# Función para obtener la imagen desde el lienzo\n",
    "def get_drawing():\n",
    "    img = Image.fromarray(canvas.get_image_data(0, 0, 200, 200))\n",
    "    img = img.convert(\"L\")  # Convertir a escala de grises\n",
    "    img = img.resize((28, 28))  # Redimensionar a 28x28 píxeles\n",
    "    return np.array(img)  # Retorna como un array NumPy\n",
    "\n",
    "# Función para predecir usando el modelo\n",
    "def predict_drawing(model, dataset):\n",
    "    # Obtener el dibujo actual del lienzo\n",
    "    img = get_drawing()\n",
    "    \n",
    "    # Preprocesar la imagen\n",
    "    img_tensor = transform(Image.fromarray(img)).unsqueeze(0)  # Agregar dimensión batch\n",
    "    \n",
    "    # Enviar la imagen al modelo para predicción\n",
    "    model.eval()  # Establecer el modelo en modo evaluación\n",
    "    with torch.no_grad():  # Desactivar gradientes para predicción\n",
    "        output = model(img_tensor)  # Obtener las predicciones\n",
    "        pred = torch.argmax(output, dim=1).item()  # Obtener la clase predicha\n",
    "    \n",
    "    # Mapear la predicción a la etiqueta correspondiente\n",
    "    label = list(dataset.label_to_idx.keys())[list(dataset.label_to_idx.values()).index(pred)]\n",
    "    print(f\"Predicción: {label}\")\n",
    "\n",
    "# Ejemplo de uso después de dibujar algo en el lienzo:\n",
    "predict_drawing(model, dataset)\n",
    "\n",
    "#Limpiar el canvas después de la prediccion\n",
    "canvas.clear()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ac846d-7299-489d-a2be-3eb90964f628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "434111056aa1469288b5f94c15657b73": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b1ab181eca0246fe90748b475bf2a383": {
      "model_module": "ipycanvas",
      "model_module_version": "^0.13",
      "model_name": "CanvasManagerModel",
      "state": {
       "_model_module_version": "^0.13",
       "_view_module": null,
       "_view_module_version": ""
      }
     },
     "d55b1d2b1718497e8a385f1b9a757647": {
      "buffers": [
       {
        "data": "iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAYAAACtWK6eAAAAAXNSR0IArs4c6QAABSJJREFUeF7t1bERwDAMxLB4/6UzgV2wfaRXIci8nM9HgMBV4LAhQOAuIBCvg8BDQCCeBwGBeAMEmoA/SHMzNSIgkJFDW7MJCKS5mRoREMjIoa3ZBATS3EyNCAhk5NDWbAICaW6mRgQEMnJoazYBgTQ3UyMCAhk5tDWbgECam6kRAYGMHNqaTUAgzc3UiIBARg5tzSYgkOZmakRAICOHtmYTEEhzMzUiIJCRQ1uzCQikuZkaERDIyKGt2QQE0txMjQgIZOTQ1mwCAmlupkYEBDJyaGs2AYE0N1MjAgIZObQ1m4BAmpupEQGBjBzamk1AIM3N1IiAQEYObc0mIJDmZmpEQCAjh7ZmExBIczM1IiCQkUNbswkIpLmZGhEQyMihrdkEBNLcTI0ICGTk0NZsAgJpbqZGBAQycmhrNgGBNDdTIwICGTm0NZuAQJqbqREBgYwc2ppNQCDNzdSIgEBGDm3NJiCQ5mZqREAgI4e2ZhMQSHMzNSIgkJFDW7MJCKS5mRoREMjIoa3ZBATS3EyNCAhk5NDWbAICaW6mRgQEMnJoazYBgTQ3UyMCAhk5tDWbgECam6kRAYGMHNqaTUAgzc3UiIBARg5tzSYgkOZmakRAICOHtmYTEEhzMzUiIJCRQ1uzCQikuZkaERDIyKGt2QQE0txMjQgIZOTQ1mwCAmlupkYEBDJyaGs2AYE0N1MjAgIZObQ1m4BAmpupEQGBjBzamk1AIM3N1IiAQEYObc0mIJDmZmpEQCAjh7ZmExBIczM1IiCQkUNbswkIpLmZGhEQyMihrdkEBNLcTI0ICGTk0NZsAgJpbqZGBAQycmhrNgGBNDdTIwICGTm0NZuAQJqbqREBgYwc2ppNQCDNzdSIgEBGDm3NJiCQ5mZqREAgI4e2ZhMQSHMzNSIgkJFDW7MJCKS5mRoREMjIoa3ZBATS3EyNCAhk5NDWbAICaW6mRgQEMnJoazYBgTQ3UyMCAhk5tDWbgECam6kRAYGMHNqaTUAgzc3UiIBARg5tzSYgkOZmakRAICOHtmYTEEhzMzUiIJCRQ1uzCQikuZkaERDIyKGt2QQE0txMjQgIZOTQ1mwCAmlupkYEBDJyaGs2AYE0N1MjAgIZObQ1m4BAmpupEQGBjBzamk1AIM3N1IiAQEYObc0mIJDmZmpEQCAjh7ZmExBIczM1IiCQkUNbswkIpLmZGhEQyMihrdkEBNLcTI0ICGTk0NZsAgJpbqZGBAQycmhrNgGBNDdTIwICGTm0NZuAQJqbqREBgYwc2ppNQCDNzdSIgEBGDm3NJiCQ5mZqREAgI4e2ZhMQSHMzNSIgkJFDW7MJCKS5mRoREMjIoa3ZBATS3EyNCAhk5NDWbAICaW6mRgQEMnJoazYBgTQ3UyMCAhk5tDWbgECam6kRAYGMHNqaTUAgzc3UiIBARg5tzSYgkOZmakRAICOHtmYTEEhzMzUiIJCRQ1uzCQikuZkaERDIyKGt2QQE0txMjQgIZOTQ1mwCAmlupkYEBDJyaGs2AYE0N1MjAgIZObQ1m4BAmpupEQGBjBzamk1AIM3N1IiAQEYObc0mIJDmZmpEQCAjh7ZmExBIczM1IiCQkUNbswkIpLmZGhEQyMihrdkEBNLcTI0ICGTk0NZsAgJpbqZGBAQycmhrNgGBNDdTIwICGTm0NZuAQJqbqREBgYwc2ppNQCDNzdSIgEBGDm3NJiCQ5mZqREAgI4e2ZhMQSHMzNSIgkJFDW7MJCKS5mRoR+AErVADJkrjltgAAAABJRU5ErkJggg==",
        "encoding": "base64",
        "path": [
         "image_data"
        ]
       }
      ],
      "model_module": "ipycanvas",
      "model_module_version": "^0.13",
      "model_name": "CanvasModel",
      "state": {
       "_canvas_manager": "IPY_MODEL_b1ab181eca0246fe90748b475bf2a383",
       "_model_module_version": "^0.13",
       "_view_module_version": "^0.13",
       "height": 200,
       "layout": "IPY_MODEL_434111056aa1469288b5f94c15657b73",
       "sync_image_data": true,
       "width": 200
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
