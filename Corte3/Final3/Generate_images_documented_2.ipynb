{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13a61a7d",
   "metadata": {},
   "source": [
    "Crear canva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8900947a-f05c-427c-a008-c4bca105c439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\leona\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\leona\\anaconda3\\lib\\site-packages (0.20.1)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.5.1-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torchaudio-2.5.1-cp312-cp312-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.4 MB 435.7 kB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.2/2.4 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.5/2.4 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 11.9 MB/s eta 0:00:00\n",
      "Installing collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0807c95-ee57-4854-aac1-c72ad4c6b225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "686b090f-9205-4053-ade8-6916d9a6a6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329945b7437442e48668554fb199ae32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=200, sync_image_data=True, width=200)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Esta celda realiza las siguientes operaciones:\n",
    "# - Configura un lienzo interactivo para dibujar formas.\n",
    "# - Implementa funciones para capturar dibujos y procesarlos.\n",
    "\n",
    "from ipycanvas import Canvas # Proporciona la funcionalidad para crear lienzos interactivos en Jupyter Notebook.\n",
    "from PIL import Image, ImageDraw # Se utiliza para trabajar con imágenes, como convertir de matrices a imágenes y viceversa.\n",
    "import numpy as np # Es esencial para realizar operaciones matemáticas en arreglos (como las imágenes que se representan como matrices).\n",
    "import os # Permite interactuar con el sistema operativo, como crear directorios.\n",
    "\n",
    "# Se crea un lienzo blanco de 200x200 píxeles.\n",
    "canvas = Canvas(width=200, height=200, background_color=\"white\", sync_image_data = True)\n",
    "# La opción sync_image_data = True asegura que los cambios en el lienzo se reflejen en la representación de la imagen.\n",
    "\n",
    "# Función para capturar el dibujo como imagen\n",
    "def get_drawing(): # Obtiene los datos de la imagen del lienzo.\n",
    "    # Convierte la imagen del lienzo a una matriz NumPy y luego a imagen de escala de grises    \n",
    "    img = Image.fromarray(canvas.get_image_data(0, 0, 200, 200))\n",
    "    # Convertir la imagen a escala de grises (L)\n",
    "    img = img.convert(\"L\")\n",
    "    img = img.resize((28, 28))  # Redimensionar a 28x28 píxeles\n",
    "    # Convertir la imagen en escala de grises a una matriz NumPy\n",
    "    return np.array(img)\n",
    "\n",
    "# Función para guardar el dibujo\n",
    "def save_drawing(class_name, count): # Crea un directorio para almacenar las imágenes de la clase especificada (por ejemplo, \"0\", \"1\", \"2\" para dígitos).\n",
    "    # Crear directorio si no existe\n",
    "    os.makedirs(f\"data/{class_name}\", exist_ok=True) # exist_ok=True evita errores si el directorio ya existe.\n",
    "    # Obtiene el dibujo del lienzo utilizando get_drawing().\n",
    "    img = get_drawing()\n",
    "    \n",
    "    # Guardar la imagen en el directorio especificado\n",
    "    filepath = f\"data/{class_name}/{count}.png\"\n",
    "    Image.fromarray(img).save(filepath)\n",
    "    print(f\"Dibujo guardado en: {filepath}\")\n",
    "\n",
    "\n",
    "# Variable para almacenar la última posición\n",
    "last_x, last_y = None, None\n",
    "\n",
    "# Función para dibujar en el lienzo\n",
    "def on_mouse_down(x, y): \n",
    "    global last_x, last_y\n",
    "    canvas.fill_style = \"black\"\n",
    "    last_x, last_y = x, y  # Guardar la posición inicial cuando se presiona el botón del mouse\n",
    "\n",
    "def on_mouse_move(x, y): # Se definen funciones para manejar los eventos de clic, movimiento y liberación del mouse.\n",
    "    global last_x, last_y\n",
    "    if last_x is not None and last_y is not None:\n",
    "        canvas.stroke_style = \"black\"\n",
    "        canvas.line_width = 5\n",
    "        canvas.begin_path()\n",
    "        canvas.move_to(last_x, last_y)\n",
    "        canvas.line_to(x, y)\n",
    "        canvas.stroke()\n",
    "        last_x, last_y = x, y  # Actualizar la posición de la última coordenada\n",
    "\n",
    "def on_mouse_up(x, y):\n",
    "    global last_x, last_y\n",
    "    last_x, last_y = None, None  # Resetear cuando se suelta el mouse\n",
    "\n",
    "# Asignar los eventos de mouse al lienzo\n",
    "canvas.on_mouse_down(on_mouse_down)\n",
    "canvas.on_mouse_move(on_mouse_move)\n",
    "canvas.on_mouse_up(on_mouse_up)\n",
    "\n",
    "# Mostrar el lienzo\n",
    "display(canvas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63ff3f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dibujo guardado en: data/square/5.png\n"
     ]
    }
   ],
   "source": [
    "# Se guarda imagen en un directorio específico.\n",
    "save_drawing(\"square\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ccbae4",
   "metadata": {},
   "source": [
    "Generar Imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bff446b-b360-4b75-b0f1-9b76ea760c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta celda realiza las siguientes operaciones:\n",
    "# - Genera datos sintéticos de varias formas geométricas (círculos, cuadrados, etc.).\n",
    "# - Guarda estas imágenes en una estructura de carpetas.\n",
    "\n",
    "# Generar formas sintéticas\n",
    "\n",
    "def generate_synthetic_data(class_name, count): # Esta función genera y guarda imágenes de formas geométricas básicas en blanco y negro.\n",
    "    os.makedirs(f\"data/{class_name}\", exist_ok=True)\n",
    "    for i in range(count):\n",
    "        # Crear una imagen en blanco\n",
    "        img = Image.new(\"L\", (28, 28), \"white\") # Imagen de  28X28 píxeles en escala de grises \"L\"\n",
    "        draw = ImageDraw.Draw(img) # Crea un objeto ImageDraw.Draw para dibujar en la imagen.\n",
    "\n",
    "        # Nombre de la clase de la forma geométrica a generar. Debe ser \"circle\", \"square\", \"triangle\" o \"star\"\n",
    "        if class_name == \"circle\":\n",
    "            draw.ellipse((5, 5, 23, 23), outline=\"black\", fill=\"black\")\n",
    "        elif class_name == \"square\":\n",
    "            draw.rectangle((5, 5, 23, 23), outline=\"black\", fill=\"black\")\n",
    "        elif class_name == \"triangle\":\n",
    "            draw.polygon([(14, 5), (5, 23), (23, 23)], outline=\"black\", fill=\"black\")\n",
    "        elif class_name == \"star\":\n",
    "            draw.polygon([(14, 5), (10, 20), (5, 14), (23, 14), (18, 20)], outline=\"black\", fill=\"black\")\n",
    "\n",
    "        # Guardar la imagen\n",
    "        filepath = f\"data/{class_name}/{i}.png\" # Ruta del archivo \n",
    "        img.save(filepath) # Acá se guarda la imagen en la ruta \n",
    "        #print(f\"Dibujo sintético guardado en: {filepath}\")\n",
    "\n",
    "# Generar 100 imágenes sintéticas por clase\n",
    "generate_synthetic_data(\"circle\", 100)\n",
    "generate_synthetic_data(\"square\", 100)\n",
    "generate_synthetic_data(\"triangle\", 100)\n",
    "generate_synthetic_data(\"star\", 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db075717",
   "metadata": {},
   "source": [
    "Cargar imágenes en el Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ba2876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta celda realiza las siguientes operaciones:\n",
    "# - Define una clase personalizada para cargar imágenes en un dataset.\n",
    "# - Aplica transformaciones como normalización y conversión a tensor.\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "class DrawingDataset(Dataset): # root_dir es la ruta del directorio raíz que contiene las imágenes del dataset.\n",
    "    def __init__(self, root_dir, transform=None): # Metodo que inicializa el dataset, verifica exisitencia de la imagen \n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform # Del objeto de transforms de torchvision para transformaciones que se aplicarán a las imágenes cargadas.\n",
    "        self.filepaths = glob.glob(os.path.join(root_dir, \"*\", \"*.png\")) # Lista de rutas de las imágenes en el dataset\n",
    "\n",
    "        if not self.filepaths:\n",
    "            raise ValueError(f\"No se encontraron imágenes en {root_dir}. Verifica la estructura del directorio.\")\n",
    "            \n",
    "        # Lista de etiquetas correspondientes a cada imagen, basadas en el nombre del directorio padre\n",
    "        self.labels = [os.path.basename(os.path.dirname(path)) for path in self.filepaths]\n",
    "        # Diccionario que mapea cada etiqueta única a un índice entero.\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(set(self.labels))}\n",
    "\n",
    "    # Devuelve el tamaño del dataset (número total de imágenes).\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "\n",
    "    # Obtiene una imagen y su etiqueta correspondiente a un índice específico\n",
    "    def __getitem__(self, idx):\n",
    "            # Abrir imagen y convertirla a escala de grises\n",
    "            img = Image.open(self.filepaths[idx]).convert(\"L\")  # Convertir a escala de grises (1 canal)\n",
    "            label = self.label_to_idx[self.labels[idx]] # Obtiene la etiqueta del diccionario\n",
    "            \n",
    "            # Aplicar transformaciones\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            else:\n",
    "                # Si no hay transformaciones, convierte la imagen a un tensor usando\n",
    "                img = transforms.ToTensor()(img)\n",
    "            \n",
    "            return img, label # Devuelve una tupla con la imagen (como tensor) y su etiqueta (como entero).\n",
    "# Transformaciones para normalizar imágenes\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),       # Asegurar tamaño 28x28\n",
    "    transforms.ToTensor(),            # Convertir a tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalizar\n",
    "])\n",
    "\n",
    "# Cargar el dataset\n",
    "dataset = DrawingDataset(root_dir=\"data\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f0293",
   "metadata": {},
   "source": [
    "Paso 3: Crear y Entrenar el Modelo CNN Definimos un modelo básico en PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d235f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsando dispositivo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# Imprime el dispositivo utilizado para el entrenamiento.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Enviar el modelo al dispositivo\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Función para entrenar el modelo CNN.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Dataloader: Cargador de datos (DataLoader) creado a partir del dataset DrawingDataset.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Criterion: Función de pérdida para evaluar el error del modelo (definido más adelante).\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Optimizer: Optimizador para ajustar los pesos del modelo durante el entrenamiento.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Epochs (opcional, int): Número de épocas para entrenar el modelo (valor por defecto 5).\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(model, dataloader, criterion, optimizer, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Esta celda realiza las siguientes operaciones:\n",
    "# - Define un modelo básico de PyTorch y entrena una red neuronal CNN.\n",
    "# - Imprime estadísticas como pérdida y precisión por época.\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "    # Verificar si GPU está disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\") # Imprime el dispositivo utilizado para el entrenamiento.\n",
    "\n",
    "# Enviar el modelo al dispositivo\n",
    "model.to(device)\n",
    "\n",
    "# Función para entrenar el modelo CNN.\n",
    "# Dataloader: Cargador de datos (DataLoader) creado a partir del dataset DrawingDataset.\n",
    "# Criterion: Función de pérdida para evaluar el error del modelo (definido más adelante).\n",
    "# Optimizer: Optimizador para ajustar los pesos del modelo durante el entrenamiento.\n",
    "# Epochs (opcional, int): Número de épocas para entrenar el modelo (valor por defecto 5).\n",
    "    \n",
    "def train_model(model, dataloader, criterion, optimizer, epochs=5):\n",
    "    model.train()  # Modo entrenamiento\n",
    "    for epoch in range(epochs):\n",
    "        # Variable para acumular la pérdida total durante una época.\n",
    "        running_loss = 0.0\n",
    "        # Variable para acumular el número de predicciones correctas.\n",
    "        correct = 0\n",
    "        # total = 0 # Variable para acumular el número total de imágenes en una época.\n",
    "        total = 0\n",
    "\n",
    "        # Envía las imágenes y etiquetas al dispositivo seleccionado (GPU o CPU) para el procesamiento.\n",
    "        for images, labels in dataloader:\n",
    "            # Enviar imágenes y etiquetas al dispositivo\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Pone a cero los gradientes del optimizador antes de cada paso de retropropagación.\n",
    "            # Forward\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images) #  Realiza una pasada hacia adelante por el modelo para obtener las salidas (predicciones)\n",
    "            loss = criterion(outputs, labels) # Calcula la pérdida entre las salidas del modelo y las etiquetas reales utilizando la función de pérdida.\n",
    "            \n",
    "            # Backward y optimización\n",
    "            loss.backward() # Calcula los gradientes de la pérdida con respecto a los pesos del modelo.\n",
    "            optimizer.step() # Actualiza los pesos del modelo utilizando el optimizador y los gradientes calculados.\n",
    "            \n",
    "            # Estadísticas\n",
    "            running_loss += loss.item() # Acumula la pérdida del lote actual.\n",
    "            _, predicted = torch.max(outputs, 1) # Obtiene las clases predichas (índice de la clase con mayor probabilidad).\n",
    "            total += labels.size(0) # Contabiliza el número de imágenes en el lote actual.\n",
    "            correct += (predicted == labels).sum().item() # Contabiliza el número de predicciones correctas en el lote actual.\n",
    "\n",
    "        accuracy = 100 * correct / total #  Calcula la precisión del modelo para la época actual.\n",
    "        # Imprime el número de la época actual, la pérdida promedio y la precisión para la época.\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(dataloader):.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, dataloader, criterion, optimizer, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e5da43",
   "metadata": {},
   "source": [
    "Entrenamos el modelo con los datos capturados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "062babe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329945b7437442e48668554fb199ae32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=200, image_data=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xc8\\x00\\x00\\x00\\xc8\\x08\\x06\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mostrar el lienzo\n",
    "display(canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09e826ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicción: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Ejemplo de uso después de dibujar algo en el lienzo:\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m predict_drawing(model, dataset)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#Limpiar el canvas después de la prediccion\u001b[39;00m\n\u001b[0;32m     45\u001b[0m canvas\u001b[38;5;241m.\u001b[39mclear()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Esta celda realiza las siguientes operaciones:\n",
    "# - Utiliza un modelo previamente entrenado para predecir la clase de un dibujo en el lienzo.\n",
    "# - Limpia el lienzo después de realizar una predicción.\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Crear la transformación que se debe aplicar al dibujo\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                  # Convierte a tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))    # Normaliza (ajusta según las necesidades del modelo)\n",
    "])\n",
    "\n",
    "# Función para obtener la imagen desde el lienzo\n",
    "def get_drawing():\n",
    "    img = Image.fromarray(canvas.get_image_data(0, 0, 200, 200))\n",
    "    img = img.convert(\"L\")  # Convertir a escala de grises\n",
    "    img = img.resize((28, 28))  # Redimensionar a 28x28 píxeles\n",
    "    return np.array(img)  # Retorna como un array NumPy\n",
    "\n",
    "# Función para predecir usando el modelo\n",
    "def predict_drawing(model, dataset):\n",
    "    # Obtener el dibujo actual del lienzo\n",
    "    img = get_drawing()\n",
    "    \n",
    "    # Preprocesar la imagen\n",
    "    img_tensor = transform(Image.fromarray(img)).unsqueeze(0)  # Agregar dimensión batch\n",
    "    \n",
    "    # Enviar la imagen al modelo para predicción\n",
    "    model.eval()  # Establecer el modelo en modo evaluación\n",
    "    with torch.no_grad():  # Desactivar gradientes para predicción\n",
    "        output = model(img_tensor)  # Obtener las predicciones\n",
    "        pred = torch.argmax(output, dim=1).item()  # Obtener la clase predicha\n",
    "    \n",
    "    # Mapear la predicción a la etiqueta correspondiente\n",
    "    label = list(dataset.label_to_idx.keys())[list(dataset.label_to_idx.values()).index(pred)]\n",
    "    print(f\"Predicción: {label}\")\n",
    "\n",
    "# Ejemplo de uso después de dibujar algo en el lienzo:\n",
    "predict_drawing(model, dataset)\n",
    "\n",
    "#Limpiar el canvas después de la prediccion\n",
    "canvas.clear()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d70366a-6749-4a34-aac9-4772ad49ba5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "329945b7437442e48668554fb199ae32": {
      "buffers": [
       {
        "data": "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",
        "encoding": "base64",
        "path": [
         "image_data"
        ]
       }
      ],
      "model_module": "ipycanvas",
      "model_module_version": "^0.13",
      "model_name": "CanvasModel",
      "state": {
       "_canvas_manager": "IPY_MODEL_92b6b541181343a789ddeeeadb977d3d",
       "_model_module_version": "^0.13",
       "_view_module_version": "^0.13",
       "height": 200,
       "layout": "IPY_MODEL_7455897a12f844bb868eb7fbe3ad02a1",
       "sync_image_data": true,
       "width": 200
      }
     },
     "6c909eb4ab0c45628a6d2f8492572334": {
      "buffers": [
       {
        "data": "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",
        "encoding": "base64",
        "path": [
         "image_data"
        ]
       }
      ],
      "model_module": "ipycanvas",
      "model_module_version": "^0.13",
      "model_name": "CanvasModel",
      "state": {
       "_canvas_manager": "IPY_MODEL_92b6b541181343a789ddeeeadb977d3d",
       "_model_module_version": "^0.13",
       "_view_module_version": "^0.13",
       "height": 200,
       "layout": "IPY_MODEL_8197c4b34f464def8963c2c787e8eab7",
       "sync_image_data": true,
       "width": 200
      }
     },
     "7455897a12f844bb868eb7fbe3ad02a1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7ffb5d8eedba45aaaf5332783a4613fe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8197c4b34f464def8963c2c787e8eab7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "92b6b541181343a789ddeeeadb977d3d": {
      "model_module": "ipycanvas",
      "model_module_version": "^0.13",
      "model_name": "CanvasManagerModel",
      "state": {
       "_model_module_version": "^0.13",
       "_view_module": null,
       "_view_module_version": ""
      }
     },
     "a704dc0ba0c6482e820f71cf76b424be": {
      "model_module": "ipycanvas",
      "model_module_version": "^0.13",
      "model_name": "CanvasModel",
      "state": {
       "_canvas_manager": "IPY_MODEL_92b6b541181343a789ddeeeadb977d3d",
       "_model_module_version": "^0.13",
       "_view_module_version": "^0.13",
       "height": 200,
       "layout": "IPY_MODEL_c3889b11094e480c9e51bb7a49c77b19",
       "sync_image_data": true,
       "width": 200
      }
     },
     "c3889b11094e480c9e51bb7a49c77b19": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d8b84055817d40f1a0e6bdda355d1a45": {
      "buffers": [
       {
        "data": "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",
        "encoding": "base64",
        "path": [
         "image_data"
        ]
       }
      ],
      "model_module": "ipycanvas",
      "model_module_version": "^0.13",
      "model_name": "CanvasModel",
      "state": {
       "_canvas_manager": "IPY_MODEL_92b6b541181343a789ddeeeadb977d3d",
       "_model_module_version": "^0.13",
       "_view_module_version": "^0.13",
       "height": 200,
       "layout": "IPY_MODEL_7ffb5d8eedba45aaaf5332783a4613fe",
       "sync_image_data": true,
       "width": 200
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
