{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13a61a7d",
   "metadata": {},
   "source": [
    "Crear canva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8900947a-f05c-427c-a008-c4bca105c439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\leona\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\leona\\anaconda3\\lib\\site-packages (0.20.1)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.5.1-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torchaudio-2.5.1-cp312-cp312-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.4 MB 435.7 kB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.2/2.4 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.5/2.4 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 11.9 MB/s eta 0:00:00\n",
      "Installing collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0807c95-ee57-4854-aac1-c72ad4c6b225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "686b090f-9205-4053-ade8-6916d9a6a6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58eb946319244b6a32647c5255f8996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=200, sync_image_data=True, width=200)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Esta celda realiza las siguientes operaciones:\n",
    "# - Configura un lienzo interactivo para dibujar formas.\n",
    "# - Implementa funciones para capturar dibujos y procesarlos.\n",
    "\n",
    "from ipycanvas import Canvas # Proporciona la funcionalidad para crear lienzos interactivos en Jupyter Notebook.\n",
    "from PIL import Image, ImageDraw # Se utiliza para trabajar con imágenes, como convertir de matrices a imágenes y viceversa.\n",
    "import numpy as np # Es esencial para realizar operaciones matemáticas en arreglos (como las imágenes que se representan como matrices).\n",
    "import os # Permite interactuar con el sistema operativo, como crear directorios.\n",
    "\n",
    "# Se crea un lienzo blanco de 200x200 píxeles.\n",
    "canvas = Canvas(width=200, height=200, background_color=\"white\", sync_image_data = True)\n",
    "# La opción sync_image_data = True asegura que los cambios en el lienzo se reflejen en la representación de la imagen.\n",
    "\n",
    "# Función para capturar el dibujo como imagen\n",
    "def get_drawing(): # Obtiene los datos de la imagen del lienzo.\n",
    "    # Convierte la imagen del lienzo a una matriz NumPy y luego a imagen de escala de grises    \n",
    "    img = Image.fromarray(canvas.get_image_data(0, 0, 200, 200))\n",
    "    # Convertir la imagen a escala de grises (L)\n",
    "    img = img.convert(\"L\")\n",
    "    img = img.resize((28, 28))  # Redimensionar a 28x28 píxeles\n",
    "    # Convertir la imagen en escala de grises a una matriz NumPy\n",
    "    return np.array(img)\n",
    "\n",
    "# Función para guardar el dibujo\n",
    "def save_drawing(class_name, count): # Crea un directorio para almacenar las imágenes de la clase especificada (por ejemplo, \"0\", \"1\", \"2\" para dígitos).\n",
    "    # Crear directorio si no existe\n",
    "    os.makedirs(f\"data/{class_name}\", exist_ok=True) # exist_ok=True evita errores si el directorio ya existe.\n",
    "    # Obtiene el dibujo del lienzo utilizando get_drawing().\n",
    "    img = get_drawing()\n",
    "    \n",
    "    # Guardar la imagen en el directorio especificado\n",
    "    filepath = f\"data/{class_name}/{count}.png\"\n",
    "    Image.fromarray(img).save(filepath)\n",
    "    print(f\"Dibujo guardado en: {filepath}\")\n",
    "\n",
    "\n",
    "# Variable para almacenar la última posición\n",
    "last_x, last_y = None, None\n",
    "\n",
    "# Función para dibujar en el lienzo\n",
    "def on_mouse_down(x, y): \n",
    "    global last_x, last_y\n",
    "    canvas.fill_style = \"black\"\n",
    "    last_x, last_y = x, y  # Guardar la posición inicial cuando se presiona el botón del mouse\n",
    "\n",
    "def on_mouse_move(x, y): # Se definen funciones para manejar los eventos de clic, movimiento y liberación del mouse.\n",
    "    global last_x, last_y\n",
    "    if last_x is not None and last_y is not None:\n",
    "        canvas.stroke_style = \"black\"\n",
    "        canvas.line_width = 5\n",
    "        canvas.begin_path()\n",
    "        canvas.move_to(last_x, last_y)\n",
    "        canvas.line_to(x, y)\n",
    "        canvas.stroke()\n",
    "        last_x, last_y = x, y  # Actualizar la posición de la última coordenada\n",
    "\n",
    "def on_mouse_up(x, y):\n",
    "    global last_x, last_y\n",
    "    last_x, last_y = None, None  # Resetear cuando se suelta el mouse\n",
    "\n",
    "# Asignar los eventos de mouse al lienzo\n",
    "canvas.on_mouse_down(on_mouse_down)\n",
    "canvas.on_mouse_move(on_mouse_move)\n",
    "canvas.on_mouse_up(on_mouse_up)\n",
    "\n",
    "# Mostrar el lienzo\n",
    "display(canvas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63ff3f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dibujo guardado en: data/square/5.png\n"
     ]
    }
   ],
   "source": [
    "# Se guarda imagen en un directorio específico.\n",
    "save_drawing(\"square\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ccbae4",
   "metadata": {},
   "source": [
    "Generar Imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bff446b-b360-4b75-b0f1-9b76ea760c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta celda realiza las siguientes operaciones:\n",
    "# - Genera datos sintéticos de varias formas geométricas (círculos, cuadrados, etc.).\n",
    "# - Guarda estas imágenes en una estructura de carpetas.\n",
    "\n",
    "# Generar formas sintéticas\n",
    "\n",
    "def generate_synthetic_data(class_name, count): # Esta función genera y guarda imágenes de formas geométricas básicas en blanco y negro.\n",
    "    os.makedirs(f\"data/{class_name}\", exist_ok=True)\n",
    "    for i in range(count):\n",
    "        # Crear una imagen en blanco\n",
    "        img = Image.new(\"L\", (28, 28), \"white\") # Imagen de  28X28 píxeles en escala de grises \"L\"\n",
    "        draw = ImageDraw.Draw(img) # Crea un objeto ImageDraw.Draw para dibujar en la imagen.\n",
    "\n",
    "        # Nombre de la clase de la forma geométrica a generar. Debe ser \"circle\", \"square\", \"triangle\" o \"star\"\n",
    "        if class_name == \"circle\":\n",
    "            draw.ellipse((5, 5, 23, 23), outline=\"black\", fill=\"black\")\n",
    "        elif class_name == \"square\":\n",
    "            draw.rectangle((5, 5, 23, 23), outline=\"black\", fill=\"black\")\n",
    "        elif class_name == \"triangle\":\n",
    "            draw.polygon([(14, 5), (5, 23), (23, 23)], outline=\"black\", fill=\"black\")\n",
    "        elif class_name == \"star\":\n",
    "            draw.polygon([(14, 5), (10, 20), (5, 14), (23, 14), (18, 20)], outline=\"black\", fill=\"black\")\n",
    "\n",
    "        # Guardar la imagen\n",
    "        filepath = f\"data/{class_name}/{i}.png\" # Ruta del archivo \n",
    "        img.save(filepath) # Acá se guarda la imagen en la ruta \n",
    "        #print(f\"Dibujo sintético guardado en: {filepath}\")\n",
    "\n",
    "# Generar 100 imágenes sintéticas por clase\n",
    "generate_synthetic_data(\"circle\", 100)\n",
    "generate_synthetic_data(\"square\", 100)\n",
    "generate_synthetic_data(\"triangle\", 100)\n",
    "generate_synthetic_data(\"star\", 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db075717",
   "metadata": {},
   "source": [
    "Cargar imágenes en el Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ba2876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta celda realiza las siguientes operaciones:\n",
    "# - Define una clase personalizada para cargar imágenes en un dataset.\n",
    "# - Aplica transformaciones como normalización y conversión a tensor.\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "class DrawingDataset(Dataset): # root_dir es la ruta del directorio raíz que contiene las imágenes del dataset.\n",
    "    def __init__(self, root_dir, transform=None): # Metodo que inicializa el dataset, verifica exisitencia de la imagen \n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform # Del objeto de transforms de torchvision para transformaciones que se aplicarán a las imágenes cargadas.\n",
    "        self.filepaths = glob.glob(os.path.join(root_dir, \"*\", \"*.png\")) # Lista de rutas de las imágenes en el dataset\n",
    "\n",
    "        if not self.filepaths:\n",
    "            raise ValueError(f\"No se encontraron imágenes en {root_dir}. Verifica la estructura del directorio.\")\n",
    "            \n",
    "        # Lista de etiquetas correspondientes a cada imagen, basadas en el nombre del directorio padre\n",
    "        self.labels = [os.path.basename(os.path.dirname(path)) for path in self.filepaths]\n",
    "        # Diccionario que mapea cada etiqueta única a un índice entero.\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(set(self.labels))}\n",
    "\n",
    "    # Devuelve el tamaño del dataset (número total de imágenes).\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "\n",
    "    # Obtiene una imagen y su etiqueta correspondiente a un índice específico\n",
    "    def __getitem__(self, idx):\n",
    "            # Abrir imagen y convertirla a escala de grises\n",
    "            img = Image.open(self.filepaths[idx]).convert(\"L\")  # Convertir a escala de grises (1 canal)\n",
    "            label = self.label_to_idx[self.labels[idx]] # Obtiene la etiqueta del diccionario\n",
    "            \n",
    "            # Aplicar transformaciones\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            else:\n",
    "                # Si no hay transformaciones, convierte la imagen a un tensor usando\n",
    "                img = transforms.ToTensor()(img)\n",
    "            \n",
    "            return img, label # Devuelve una tupla con la imagen (como tensor) y su etiqueta (como entero).\n",
    "# Transformaciones para normalizar imágenes\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),       # Asegurar tamaño 28x28\n",
    "    transforms.ToTensor(),            # Convertir a tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalizar\n",
    "])\n",
    "\n",
    "# Cargar el dataset\n",
    "dataset = DrawingDataset(root_dir=\"data\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f0293",
   "metadata": {},
   "source": [
    "Paso 3: Crear y Entrenar el Modelo CNN Definimos un modelo básico en PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28cbcd2c-87b6-4aa6-a664-be00736ced06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)  # Entrada 1 canal, salida 16 canales\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)        # Pooling 2x2\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1) # Entrada 16 canales, salida 32 canales\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)                   # Capa totalmente conectada\n",
    "        self.fc2 = nn.Linear(128, num_classes)                  # Capa de salida\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Primera capa convolucional con ReLU y pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Segunda capa convolucional con ReLU y pooling\n",
    "        x = x.view(-1, 32 * 7 * 7)           # Aplanar para la capa totalmente conectada\n",
    "        x = F.relu(self.fc1(x))              # Primera capa totalmente conectada\n",
    "        x = self.fc2(x)                      # Capa de salida (sin softmax)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d1f0d9-863c-4fd7-8f88-391e15983acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar el modelo\n",
    "num_classes = len(dataset.classes)  # Número de clases en el dataset\n",
    "model = SimpleCNN(num_classes=num_classes).to(device)  # Enviar el modelo al dispositivo\n",
    "\n",
    "# Definir pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, dataloader, criterion, optimizer, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d235f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsando dispositivo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# Imprime el dispositivo utilizado para el entrenamiento.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Enviar el modelo al dispositivo\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Función para entrenar el modelo CNN.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Dataloader: Cargador de datos (DataLoader) creado a partir del dataset DrawingDataset.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Criterion: Función de pérdida para evaluar el error del modelo (definido más adelante).\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Optimizer: Optimizador para ajustar los pesos del modelo durante el entrenamiento.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Epochs (opcional, int): Número de épocas para entrenar el modelo (valor por defecto 5).\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(model, dataloader, criterion, optimizer, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Esta celda realiza las siguientes operaciones:\n",
    "# - Define un modelo básico de PyTorch y entrena una red neuronal CNN.\n",
    "# - Imprime estadísticas como pérdida y precisión por época.\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "    # Verificar si GPU está disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\") # Imprime el dispositivo utilizado para el entrenamiento.\n",
    "\n",
    "# Enviar el modelo al dispositivo\n",
    "model.to(device)\n",
    "\n",
    "# Función para entrenar el modelo CNN.\n",
    "# Dataloader: Cargador de datos (DataLoader) creado a partir del dataset DrawingDataset.\n",
    "# Criterion: Función de pérdida para evaluar el error del modelo (definido más adelante).\n",
    "# Optimizer: Optimizador para ajustar los pesos del modelo durante el entrenamiento.\n",
    "# Epochs (opcional, int): Número de épocas para entrenar el modelo (valor por defecto 5).\n",
    "    \n",
    "def train_model(model, dataloader, criterion, optimizer, epochs=5):\n",
    "    model.train()  # Modo entrenamiento\n",
    "    for epoch in range(epochs):\n",
    "        # Variable para acumular la pérdida total durante una época.\n",
    "        running_loss = 0.0\n",
    "        # Variable para acumular el número de predicciones correctas.\n",
    "        correct = 0\n",
    "        # total = 0 # Variable para acumular el número total de imágenes en una época.\n",
    "        total = 0\n",
    "\n",
    "        # Envía las imágenes y etiquetas al dispositivo seleccionado (GPU o CPU) para el procesamiento.\n",
    "        for images, labels in dataloader:\n",
    "            # Enviar imágenes y etiquetas al dispositivo\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Pone a cero los gradientes del optimizador antes de cada paso de retropropagación.\n",
    "            # Forward\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images) #  Realiza una pasada hacia adelante por el modelo para obtener las salidas (predicciones)\n",
    "            loss = criterion(outputs, labels) # Calcula la pérdida entre las salidas del modelo y las etiquetas reales utilizando la función de pérdida.\n",
    "            \n",
    "            # Backward y optimización\n",
    "            loss.backward() # Calcula los gradientes de la pérdida con respecto a los pesos del modelo.\n",
    "            optimizer.step() # Actualiza los pesos del modelo utilizando el optimizador y los gradientes calculados.\n",
    "            \n",
    "            # Estadísticas\n",
    "            running_loss += loss.item() # Acumula la pérdida del lote actual.\n",
    "            _, predicted = torch.max(outputs, 1) # Obtiene las clases predichas (índice de la clase con mayor probabilidad).\n",
    "            total += labels.size(0) # Contabiliza el número de imágenes en el lote actual.\n",
    "            correct += (predicted == labels).sum().item() # Contabiliza el número de predicciones correctas en el lote actual.\n",
    "\n",
    "        accuracy = 100 * correct / total #  Calcula la precisión del modelo para la época actual.\n",
    "        # Imprime el número de la época actual, la pérdida promedio y la precisión para la época.\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(dataloader):.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, dataloader, criterion, optimizer, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e5da43",
   "metadata": {},
   "source": [
    "Entrenamos el modelo con los datos capturados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "062babe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329945b7437442e48668554fb199ae32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=200, image_data=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xc8\\x00\\x00\\x00\\xc8\\x08\\x06\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mostrar el lienzo\n",
    "display(canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09e826ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicción: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Ejemplo de uso después de dibujar algo en el lienzo:\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m predict_drawing(model, dataset)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#Limpiar el canvas después de la prediccion\u001b[39;00m\n\u001b[0;32m     45\u001b[0m canvas\u001b[38;5;241m.\u001b[39mclear()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Esta celda realiza las siguientes operaciones:\n",
    "# - Utiliza un modelo previamente entrenado para predecir la clase de un dibujo en el lienzo.\n",
    "# - Limpia el lienzo después de realizar una predicción.\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Crear la transformación que se debe aplicar al dibujo\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                  # Convierte a tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))    # Normaliza (ajusta según las necesidades del modelo)\n",
    "])\n",
    "\n",
    "# Función para obtener la imagen desde el lienzo\n",
    "def get_drawing():\n",
    "    img = Image.fromarray(canvas.get_image_data(0, 0, 200, 200))\n",
    "    img = img.convert(\"L\")  # Convertir a escala de grises\n",
    "    img = img.resize((28, 28))  # Redimensionar a 28x28 píxeles\n",
    "    return np.array(img)  # Retorna como un array NumPy\n",
    "\n",
    "# Función para predecir usando el modelo\n",
    "def predict_drawing(model, dataset):\n",
    "    # Obtener el dibujo actual del lienzo\n",
    "    img = get_drawing()\n",
    "    \n",
    "    # Preprocesar la imagen\n",
    "    img_tensor = transform(Image.fromarray(img)).unsqueeze(0)  # Agregar dimensión batch\n",
    "    \n",
    "    # Enviar la imagen al modelo para predicción\n",
    "    model.eval()  # Establecer el modelo en modo evaluación\n",
    "    with torch.no_grad():  # Desactivar gradientes para predicción\n",
    "        output = model(img_tensor)  # Obtener las predicciones\n",
    "        pred = torch.argmax(output, dim=1).item()  # Obtener la clase predicha\n",
    "    \n",
    "    # Mapear la predicción a la etiqueta correspondiente\n",
    "    label = list(dataset.label_to_idx.keys())[list(dataset.label_to_idx.values()).index(pred)]\n",
    "    print(f\"Predicción: {label}\")\n",
    "\n",
    "# Ejemplo de uso después de dibujar algo en el lienzo:\n",
    "predict_drawing(model, dataset)\n",
    "\n",
    "#Limpiar el canvas después de la prediccion\n",
    "canvas.clear()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d70366a-6749-4a34-aac9-4772ad49ba5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "a58eb946319244b6a32647c5255f8996": {
      "buffers": [
       {
        "data": "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",
        "encoding": "base64",
        "path": [
         "image_data"
        ]
       }
      ],
      "model_module": "ipycanvas",
      "model_module_version": "^0.13",
      "model_name": "CanvasModel",
      "state": {
       "_canvas_manager": "IPY_MODEL_cf6d602cbc7044cc9d620c901a8b5a06",
       "_model_module_version": "^0.13",
       "_view_module_version": "^0.13",
       "height": 200,
       "layout": "IPY_MODEL_c1641e32f31a43209024c9254c8df9b4",
       "sync_image_data": true,
       "width": 200
      }
     },
     "c1641e32f31a43209024c9254c8df9b4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cf6d602cbc7044cc9d620c901a8b5a06": {
      "model_module": "ipycanvas",
      "model_module_version": "^0.13",
      "model_name": "CanvasManagerModel",
      "state": {
       "_model_module_version": "^0.13",
       "_view_module": null,
       "_view_module_version": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
