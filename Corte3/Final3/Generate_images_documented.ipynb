{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13a61a7d",
   "metadata": {},
   "source": [
    "Crear canva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "686b090f-9205-4053-ade8-6916d9a6a6e9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c43881655dc4709a2c5394315761dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=200, sync_image_data=True, width=200)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Esta celda realiza las siguientes operaciones:\n",
    "# - Configura un lienzo interactivo para dibujar formas.\n",
    "# - Implementa funciones para capturar dibujos y procesarlos.\n",
    "\n",
    "from ipycanvas import Canvas # Proporciona la funcionalidad para crear lienzos interactivos en Jupyter Notebook.\n",
    "from PIL import Image, ImageDraw # Se utiliza para trabajar con imágenes, como convertir de matrices a imágenes y viceversa.\n",
    "import numpy as np # Es esencial para realizar operaciones matemáticas en arreglos (como las imágenes que se representan como matrices).\n",
    "import os # Permite interactuar con el sistema operativo, como crear directorios.\n",
    "\n",
    "# Se crea un lienzo blanco de 200x200 píxeles.\n",
    "canvas = Canvas(width=200, height=200, background_color=\"white\", sync_image_data = True)\n",
    "# La opción sync_image_data = True asegura que los cambios en el lienzo se reflejen en la representación de la imagen.\n",
    "\n",
    "# Función para capturar el dibujo como imagen\n",
    "def get_drawing(): # Obtiene los datos de la imagen del lienzo.\n",
    "    # Convierte la imagen del lienzo a una matriz NumPy y luego a imagen de escala de grises    \n",
    "    img = Image.fromarray(canvas.get_image_data(0, 0, 200, 200))\n",
    "    # Convertir la imagen a escala de grises (L)\n",
    "    img = img.convert(\"L\")\n",
    "    img = img.resize((28, 28))  # Redimensionar a 28x28 píxeles\n",
    "    # Convertir la imagen en escala de grises a una matriz NumPy\n",
    "    return np.array(img)\n",
    "\n",
    "# Función para guardar el dibujo\n",
    "def save_drawing(class_name, count): # Crea un directorio para almacenar las imágenes de la clase especificada (por ejemplo, \"0\", \"1\", \"2\" para dígitos).\n",
    "    # Crear directorio si no existe\n",
    "    os.makedirs(f\"data/{class_name}\", exist_ok=True) # exist_ok=True evita errores si el directorio ya existe.\n",
    "    # Obtiene el dibujo del lienzo utilizando get_drawing().\n",
    "    img = get_drawing()\n",
    "    \n",
    "    # Guardar la imagen en el directorio especificado\n",
    "    filepath = f\"data/{class_name}/{count}.png\"\n",
    "    Image.fromarray(img).save(filepath)\n",
    "    print(f\"Dibujo guardado en: {filepath}\")\n",
    "\n",
    "\n",
    "# Variable para almacenar la última posición\n",
    "last_x, last_y = None, None\n",
    "\n",
    "# Función para dibujar en el lienzo\n",
    "def on_mouse_down(x, y): \n",
    "    global last_x, last_y\n",
    "    canvas.fill_style = \"black\"\n",
    "    last_x, last_y = x, y  # Guardar la posición inicial cuando se presiona el botón del mouse\n",
    "\n",
    "def on_mouse_move(x, y): # Se definen funciones para manejar los eventos de clic, movimiento y liberación del mouse.\n",
    "    global last_x, last_y\n",
    "    if last_x is not None and last_y is not None:\n",
    "        canvas.stroke_style = \"black\"\n",
    "        canvas.line_width = 5\n",
    "        canvas.begin_path()\n",
    "        canvas.move_to(last_x, last_y)\n",
    "        canvas.line_to(x, y)\n",
    "        canvas.stroke()\n",
    "        last_x, last_y = x, y  # Actualizar la posición de la última coordenada\n",
    "\n",
    "def on_mouse_up(x, y):\n",
    "    global last_x, last_y\n",
    "    last_x, last_y = None, None  # Resetear cuando se suelta el mouse\n",
    "\n",
    "# Asignar los eventos de mouse al lienzo\n",
    "canvas.on_mouse_down(on_mouse_down)\n",
    "canvas.on_mouse_move(on_mouse_move)\n",
    "canvas.on_mouse_up(on_mouse_up)\n",
    "\n",
    "# Mostrar el lienzo\n",
    "display(canvas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cc7a0df-b762-43ad-8b7e-e9baf1b040f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.3449, Accuracy: 90.57%\n",
      "Epoch 2/5, Loss: 0.1569, Accuracy: 95.47%\n",
      "Epoch 3/5, Loss: 0.1094, Accuracy: 96.87%\n",
      "Epoch 4/5, Loss: 0.0836, Accuracy: 97.51%\n",
      "Epoch 5/5, Loss: 0.0663, Accuracy: 98.06%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a simple neural network model (example)\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)  # Example input size for MNIST\n",
    "        self.fc2 = nn.Linear(128, 10)    # Example output size for 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the model\n",
    "model = SimpleModel()  # Define the model here\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.view(-1))  # Flatten the images\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)  # Create DataLoader\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Example loss function\n",
    "optimizer = optim.Adam(model.parameters())  # Example optimizer\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, dataloader, criterion, optimizer, epochs=5):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Ensure device is defined\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(dataloader):.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Ensure you have a device defined (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)  # Move model to the appropriate device\n",
    "\n",
    "# Train the model\n",
    "train_model(model, dataloader, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63ff3f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dibujo guardado en: data/square/5.png\n"
     ]
    }
   ],
   "source": [
    "# Se guarda imagen en un directorio específico.\n",
    "save_drawing(\"square\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ccbae4",
   "metadata": {},
   "source": [
    "Generar Imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bff446b-b360-4b75-b0f1-9b76ea760c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta celda realiza las siguientes operaciones:\n",
    "# - Genera datos sintéticos de varias formas geométricas (círculos, cuadrados, etc.).\n",
    "# - Guarda estas imágenes en una estructura de carpetas.\n",
    "\n",
    "# Generar formas sintéticas\n",
    "\n",
    "def generate_synthetic_data(class_name, count): # Esta función genera y guarda imágenes de formas geométricas básicas en blanco y negro.\n",
    "    os.makedirs(f\"data/{class_name}\", exist_ok=True)\n",
    "    for i in range(count):\n",
    "        # Crear una imagen en blanco\n",
    "        img = Image.new(\"L\", (28, 28), \"white\") # Imagen de  28X28 píxeles en escala de grises \"L\"\n",
    "        draw = ImageDraw.Draw(img) # Crea un objeto ImageDraw.Draw para dibujar en la imagen.\n",
    "\n",
    "        # Nombre de la clase de la forma geométrica a generar. Debe ser \"circle\", \"square\", \"triangle\" o \"star\"\n",
    "        if class_name == \"circle\":\n",
    "            draw.ellipse((5, 5, 23, 23), outline=\"black\", fill=\"black\")\n",
    "        elif class_name == \"square\":\n",
    "            draw.rectangle((5, 5, 23, 23), outline=\"black\", fill=\"black\")\n",
    "        elif class_name == \"triangle\":\n",
    "            draw.polygon([(14, 5), (5, 23), (23, 23)], outline=\"black\", fill=\"black\")\n",
    "        elif class_name == \"star\":\n",
    "            draw.polygon([(14, 5), (10, 20), (5, 14), (23, 14), (18, 20)], outline=\"black\", fill=\"black\")\n",
    "\n",
    "        # Guardar la imagen\n",
    "        filepath = f\"data/{class_name}/{i}.png\" # Ruta del archivo \n",
    "        img.save(filepath) # Acá se guarda la imagen en la ruta \n",
    "        #print(f\"Dibujo sintético guardado en: {filepath}\")\n",
    "\n",
    "# Generar 100 imágenes sintéticas por clase\n",
    "generate_synthetic_data(\"circle\", 100)\n",
    "generate_synthetic_data(\"square\", 100)\n",
    "generate_synthetic_data(\"triangle\", 100)\n",
    "generate_synthetic_data(\"star\", 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db075717",
   "metadata": {},
   "source": [
    "Cargar imágenes en el Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abcb857d-8839-4118-bd04-fce397c21401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar los módulos necesarios\n",
    "import os\n",
    "from PIL import Image, ImageDraw  # Importar las clases necesarias de PIL\n",
    "\n",
    "# Esta celda realiza las siguientes operaciones:\n",
    "# - Genera datos sintéticos de varias formas geométricas (círculos, cuadrados, etc.).\n",
    "# - Guarda estas imágenes en una estructura de carpetas.\n",
    "\n",
    "# Generar formas sintéticas\n",
    "def generate_synthetic_data(class_name, count):  # Esta función genera y guarda imágenes de formas geométricas básicas en blanco y negro.\n",
    "    os.makedirs(f\"data/{class_name}\", exist_ok=True)\n",
    "    for i in range(count):\n",
    "        # Crear una imagen en blanco\n",
    "        img = Image.new(\"L\", (28, 28), \"white\")  # Imagen de 28X28 píxeles en escala de grises \"L\"\n",
    "        draw = ImageDraw.Draw(img)  # Crea un objeto ImageDraw.Draw para dibujar en la imagen.\n",
    "\n",
    "        # Nombre de la clase de la forma geométrica a generar. Debe ser \"circle\", \"square\", \"triangle\" o \"star\"\n",
    "        if class_name == \"circle\":\n",
    "            draw.ellipse((5, 5, 23, 23), outline=\"black\", fill=\"black\")\n",
    "        elif class_name == \"square\":\n",
    "            draw.rectangle((5, 5, 23, 23), outline=\"black\", fill=\"black\")\n",
    "        elif class_name == \"triangle\":\n",
    "            draw.polygon([(14, 5), (5, 23), (23, 23)], outline=\"black\", fill=\"black\")\n",
    "        elif class_name == \"star\":\n",
    "            draw.polygon([(14, 5), (10, 20), (5, 14), (23, 14), (18, 20)], outline=\"black\", fill=\"black\")\n",
    "\n",
    "        # Guardar la imagen\n",
    "        filepath = f\"data/{class_name}/{i}.png\"  # Ruta del archivo \n",
    "        img.save(filepath)  # Acá se guarda la imagen en la ruta \n",
    "        # print(f\"Dibujo sintético guardado en: {filepath}\")\n",
    "\n",
    "# Generar 100 imágenes sintéticas por clase\n",
    "generate_synthetic_data(\"circle\", 100)\n",
    "generate_synthetic_data(\"square\", 100)\n",
    "generate_synthetic_data(\"triangle\", 100)\n",
    "generate_synthetic_data(\"star\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ba2876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta celda realiza las siguientes operaciones:\n",
    "# - Define una clase personalizada para cargar imágenes en un dataset.\n",
    "# - Aplica transformaciones como normalización y conversión a tensor.\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "class DrawingDataset(Dataset): # root_dir es la ruta del directorio raíz que contiene las imágenes del dataset.\n",
    "    def __init__(self, root_dir, transform=None): # Metodo que inicializa el dataset, verifica exisitencia de la imagen \n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform # Del objeto de transforms de torchvision para transformaciones que se aplicarán a las imágenes cargadas.\n",
    "        self.filepaths = glob.glob(os.path.join(root_dir, \"*\", \"*.png\")) # Lista de rutas de las imágenes en el dataset\n",
    "\n",
    "        if not self.filepaths:\n",
    "            raise ValueError(f\"No se encontraron imágenes en {root_dir}. Verifica la estructura del directorio.\")\n",
    "            \n",
    "        # Lista de etiquetas correspondientes a cada imagen, basadas en el nombre del directorio padre\n",
    "        self.labels = [os.path.basename(os.path.dirname(path)) for path in self.filepaths]\n",
    "        # Diccionario que mapea cada etiqueta única a un índice entero.\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(set(self.labels))}\n",
    "\n",
    "    # Devuelve el tamaño del dataset (número total de imágenes).\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "\n",
    "    # Obtiene una imagen y su etiqueta correspondiente a un índice específico\n",
    "    def __getitem__(self, idx):\n",
    "            # Abrir imagen y convertirla a escala de grises\n",
    "            img = Image.open(self.filepaths[idx]).convert(\"L\")  # Convertir a escala de grises (1 canal)\n",
    "            label = self.label_to_idx[self.labels[idx]] # Obtiene la etiqueta del diccionario\n",
    "            \n",
    "            # Aplicar transformaciones\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            else:\n",
    "                # Si no hay transformaciones, convierte la imagen a un tensor usando\n",
    "                img = transforms.ToTensor()(img)\n",
    "            \n",
    "            return img, label # Devuelve una tupla con la imagen (como tensor) y su etiqueta (como entero).\n",
    "# Transformaciones para normalizar imágenes\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),       # Asegurar tamaño 28x28\n",
    "    transforms.ToTensor(),            # Convertir a tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalizar\n",
    "])\n",
    "\n",
    "# Cargar el dataset\n",
    "dataset = DrawingDataset(root_dir=\"data\", transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f0293",
   "metadata": {},
   "source": [
    "Paso 3: Crear y Entrenar el Modelo CNN Definimos un modelo básico en PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d235f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n",
      "Epoch 1/5, Loss: 0.0544, Accuracy: 98.37%\n",
      "Epoch 2/5, Loss: 0.0448, Accuracy: 98.67%\n",
      "Epoch 3/5, Loss: 0.0357, Accuracy: 98.91%\n",
      "Epoch 4/5, Loss: 0.0298, Accuracy: 99.10%\n",
      "Epoch 5/5, Loss: 0.0254, Accuracy: 99.27%\n"
     ]
    }
   ],
   "source": [
    "# Esta celda realiza las siguientes operaciones:\n",
    "# - Define un modelo básico de PyTorch y entrena una red neuronal CNN.\n",
    "# - Imprime estadísticas como pérdida y precisión por época.\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "    # Verificar si GPU está disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\") # Imprime el dispositivo utilizado para el entrenamiento.\n",
    "\n",
    "# Enviar el modelo al dispositivo\n",
    "model.to(device)\n",
    "\n",
    "# Función para entrenar el modelo CNN.\n",
    "# Dataloader: Cargador de datos (DataLoader) creado a partir del dataset DrawingDataset.\n",
    "# Criterion: Función de pérdida para evaluar el error del modelo (definido más adelante).\n",
    "# Optimizer: Optimizador para ajustar los pesos del modelo durante el entrenamiento.\n",
    "# Epochs (opcional, int): Número de épocas para entrenar el modelo (valor por defecto 5).\n",
    "    \n",
    "def train_model(model, dataloader, criterion, optimizer, epochs=5):\n",
    "    model.train()  # Modo entrenamiento\n",
    "    for epoch in range(epochs):\n",
    "        # Variable para acumular la pérdida total durante una época.\n",
    "        running_loss = 0.0\n",
    "        # Variable para acumular el número de predicciones correctas.\n",
    "        correct = 0\n",
    "        # total = 0 # Variable para acumular el número total de imágenes en una época.\n",
    "        total = 0\n",
    "\n",
    "        # Envía las imágenes y etiquetas al dispositivo seleccionado (GPU o CPU) para el procesamiento.\n",
    "        for images, labels in dataloader:\n",
    "            # Enviar imágenes y etiquetas al dispositivo\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Pone a cero los gradientes del optimizador antes de cada paso de retropropagación.\n",
    "            # Forward\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images) #  Realiza una pasada hacia adelante por el modelo para obtener las salidas (predicciones)\n",
    "            loss = criterion(outputs, labels) # Calcula la pérdida entre las salidas del modelo y las etiquetas reales utilizando la función de pérdida.\n",
    "            \n",
    "            # Backward y optimización\n",
    "            loss.backward() # Calcula los gradientes de la pérdida con respecto a los pesos del modelo.\n",
    "            optimizer.step() # Actualiza los pesos del modelo utilizando el optimizador y los gradientes calculados.\n",
    "            \n",
    "            # Estadísticas\n",
    "            running_loss += loss.item() # Acumula la pérdida del lote actual.\n",
    "            _, predicted = torch.max(outputs, 1) # Obtiene las clases predichas (índice de la clase con mayor probabilidad).\n",
    "            total += labels.size(0) # Contabiliza el número de imágenes en el lote actual.\n",
    "            correct += (predicted == labels).sum().item() # Contabiliza el número de predicciones correctas en el lote actual.\n",
    "\n",
    "        accuracy = 100 * correct / total #  Calcula la precisión del modelo para la época actual.\n",
    "        # Imprime el número de la época actual, la pérdida promedio y la precisión para la época.\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(dataloader):.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, dataloader, criterion, optimizer, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e5da43",
   "metadata": {},
   "source": [
    "Entrenamos el modelo con los datos capturados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed08a182-c350-4b9a-b194-08787e8ca6f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ellipsis' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m train_model(model, dataloader, criterion, optimizer, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 33\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader, criterion, optimizer, epochs)\u001b[0m\n\u001b[0;32m     30\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     31\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m     34\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     35\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'ellipsis' object is not iterable"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a simple neural network model (example)\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)  # Example input size for MNIST\n",
    "        self.fc2 = nn.Linear(128, 10)    # Example output size for 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the model\n",
    "model = SimpleModel()  # Define the model here\n",
    "\n",
    "# Assuming 'dataloader', 'criterion', and 'optimizer' are already defined\n",
    "# Example definitions (you would replace these with your actual data and settings)\n",
    "dataloader = ...  # Your DataLoader here\n",
    "criterion = nn.CrossEntropyLoss()  # Example loss function\n",
    "optimizer = optim.Adam(model.parameters())  # Example optimizer\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, dataloader, criterion, optimizer, epochs=5):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(dataloader):.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, dataloader, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23cc9d26-8117-4a72-950b-620ffc067917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 2.3568, Accuracy: 12.00%\n",
      "Epoch 2/5, Loss: 1.3892, Accuracy: 91.00%\n",
      "Epoch 3/5, Loss: 0.8221, Accuracy: 100.00%\n",
      "Epoch 4/5, Loss: 0.4583, Accuracy: 100.00%\n",
      "Epoch 5/5, Loss: 0.2399, Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Define a simple neural network model (example)\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)  # Example input size for MNIST\n",
    "        self.fc2 = nn.Linear(128, 10)    # Example output size for 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the model\n",
    "model = SimpleModel()  # Define the model here\n",
    "\n",
    "# Example data for demonstration (replace with your actual data)\n",
    "# Here we create random data for 100 samples, each with 784 features, and random labels\n",
    "dummy_images = torch.randn(100, 784)  # 100 samples of 784 features\n",
    "dummy_labels = torch.randint(0, 10, (100,))  # 100 random labels for 10 classes\n",
    "\n",
    "# Create a DataLoader\n",
    "dataset = TensorDataset(dummy_images, dummy_labels)  # Combine images and labels\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)  # Create DataLoader\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Example loss function\n",
    "optimizer = optim.Adam(model.parameters())  # Example optimizer\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, dataloader, criterion, optimizer, epochs=5):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(dataloader):.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Train the model\n",
    "train_model(model, dataloader, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "097bb6a6-e8bd-4bc7-a6aa-cf73f1290ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.3434, Accuracy: 90.54%\n",
      "Epoch 2/5, Loss: 0.1616, Accuracy: 95.30%\n",
      "Epoch 3/5, Loss: 0.1112, Accuracy: 96.76%\n",
      "Epoch 4/5, Loss: 0.0840, Accuracy: 97.56%\n",
      "Epoch 5/5, Loss: 0.0664, Accuracy: 98.02%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a simple neural network model (example)\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)  # Example input size for MNIST\n",
    "        self.fc2 = nn.Linear(128, 10)    # Example output size for 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the model\n",
    "model = SimpleModel()  # Define the model here\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.view(-1))  # Flatten the images\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)  # Create DataLoader\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Example loss function\n",
    "optimizer = optim.Adam(model.parameters())  # Example optimizer\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, dataloader, criterion, optimizer, epochs=5):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Ensure device is defined\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(dataloader):.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Ensure you have a device defined (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)  # Move model to the appropriate device\n",
    "\n",
    "# Train the model\n",
    "train_model(model, dataloader, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62d07e49-a5df-4f39-ac95-43488efb92ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 9.91M/9.91M [00:01<00:00, 9.41MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 28.9k/28.9k [00:00<00:00, 256kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1.65M/1.65M [00:00<00:00, 3.46MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4.54k/4.54k [00:00<?, ?B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Epoch 1/5, Loss: 0.3452, Accuracy: 90.52%\n",
      "Epoch 2/5, Loss: 0.1612, Accuracy: 95.36%\n",
      "Epoch 3/5, Loss: 0.1131, Accuracy: 96.70%\n",
      "Epoch 4/5, Loss: 0.0849, Accuracy: 97.51%\n",
      "Epoch 5/5, Loss: 0.0667, Accuracy: 97.99%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a simple neural network model (example)\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)  # Example input size for MNIST\n",
    "        self.fc2 = nn.Linear(128, 10)    # Example output size for 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the model\n",
    "model = SimpleModel()  # Define the model here\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.view(-1))  # Flatten the images\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)  # Create DataLoader\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Example loss function\n",
    "optimizer = optim.Adam(model.parameters())  # Example optimizer\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, dataloader, criterion, optimizer, epochs=5):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Ensure device is defined\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(dataloader):.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Ensure you have a device defined (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)  # Move model to the appropriate device\n",
    "\n",
    "# Train the model\n",
    "train_model(model, dataloader, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a6537f0-d942-4583-ab87-128e6e9fd19b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ellipsis' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)  \u001b[38;5;66;03m# Optimizador\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m train_model(model, dataloader, criterion, optimizer, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[1;32mIn[31], line 42\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader, criterion, optimizer, epochs)\u001b[0m\n\u001b[0;32m     39\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     40\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m     43\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Ensure device is defined\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'ellipsis' object is not iterable"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Definición de un modelo simple (ejemplo)\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(10, 2)  # Capa totalmente conectada (10 entradas, 2 salidas)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Inicializa el modelo\n",
    "model = SimpleModel()  # Asegúrate de que el modelo esté definido antes de usarlo\n",
    "\n",
    "# Definición del dataloader, criterion y optimizer (ejemplo)\n",
    "dataloader = ...  # Aquí deberías definir tu dataloader\n",
    "criterion = nn.CrossEntropyLoss()  # Función de pérdida\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Optimizador\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, dataloader, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b869a7a-4be1-429d-9340-497531b7e6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654d64cb-cd69-412d-9041-fa022a2cb517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Definición de un modelo simple (ejemplo)\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(10, 2)  # Capa totalmente conectada (10 entradas, 2 salidas)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Inicializa el modelo\n",
    "model = SimpleModel()  # Asegúrate de que el modelo esté definido antes de usarlo\n",
    "\n",
    "# Definición del dataloader, criterion y optimizer (ejemplo)\n",
    "dataloader = ...  # Aquí deberías definir tu dataloader\n",
    "criterion = nn.CrossEntropyLoss()  # Función de pérdida\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Optimizador\n",
    "\n",
    "# Definición de la función de entrenamiento\n",
    "def train_model(model, dataloader, criterion, optimizer, epochs):\n",
    "    model.train()  # Establece el modelo en modo de entrenamiento\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in dataloader:  # Itera sobre el dataloader\n",
    "            optimizer.zero_grad()  # Limpia los gradientes\n",
    "            outputs = model(inputs)  # Realiza la predicción\n",
    "            loss = criterion(outputs, labels)  # Calcula la pérdida\n",
    "            loss.backward()  # Calcula los gradientes\n",
    "            optimizer.step()  # Actualiza los parámetros del modelo\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')  # Imprime la pérdida por época\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, dataloader, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f3afaef-ddd4-4ec2-b2e4-11977995a7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 1.1295737028121948\n",
      "Epoch 2/5, Loss: 0.7443002462387085\n",
      "Epoch 3/5, Loss: 0.6539721488952637\n",
      "Epoch 4/5, Loss: 0.7315527200698853\n",
      "Epoch 5/5, Loss: 0.8042091131210327\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Definición de un modelo simple (ejemplo)\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(10, 2)  # Capa totalmente conectada (10 entradas, 2 salidas)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Inicializa el modelo\n",
    "model = SimpleModel()  # Asegúrate de que el modelo esté definido antes de usarlo\n",
    "\n",
    "# Crear datos de ejemplo\n",
    "inputs = torch.randn(100, 10)  # 100 muestras, 10 características\n",
    "labels = torch.randint(0, 2, (100,))  # 100 etiquetas (0 o 1)\n",
    "\n",
    "# Definición del dataloader\n",
    "dataset = TensorDataset(inputs, labels)  # Combina inputs y labels en un dataset\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)  # Crea el dataloader\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Función de pérdida\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Optimizador\n",
    "\n",
    "# Definición de la función de entrenamiento\n",
    "def train_model(model, dataloader, criterion, optimizer, epochs):\n",
    "    model.train()  # Establece el modelo en modo de entrenamiento\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in dataloader:  # Itera sobre el dataloader\n",
    "            optimizer.zero_grad()  # Limpia los gradientes\n",
    "            outputs = model(inputs)  # Realiza la predicción\n",
    "            loss = criterion(outputs, labels)  # Calcula la pérdida\n",
    "            loss.backward()  # Calcula los gradientes\n",
    "            optimizer.step()  # Actualiza los parámetros del modelo\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')  # Imprime la pérdida por época\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, dataloader, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d83b6cf-4294-4589-8b5d-c6cb8043a76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Definición de un modelo simple (ejemplo)\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(10, 2)  # Capa totalmente conectada (10 entradas, 2 salidas)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Inicializa el modelo\n",
    "model = SimpleModel()  # Asegúrate de que el modelo esté definido antes de usarlo\n",
    "\n",
    "# Definición del dataloader, criterion y optimizer (ejemplo)\n",
    "dataloader = ...  # Aquí deberías definir tu dataloader\n",
    "criterion = nn.CrossEntropyLoss()  # Función de pérdida\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Optimizador\n",
    "\n",
    "# Definición de la función de entrenamiento\n",
    "def train_model(model, dataloader, criterion, optimizer, epochs):\n",
    "    model.train()  # Establece el modelo en modo de entrenamiento\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in dataloader:  # Itera sobre el dataloader\n",
    "            optimizer.zero_grad()  # Limpia los gradientes\n",
    "            outputs = model(inputs)  # Realiza la predicción\n",
    "            loss = criterion(outputs, labels)  # Calcula la pérdida\n",
    "            loss.backward()  # Calcula los gradientes\n",
    "            optimizer.step()  # Actualiza los parámetros del modelo\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')  # Imprime la pérdida por época\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, dataloader, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0525f0ad-ae15-471b-8e52-f5b9bb5c7f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.7226508855819702\n",
      "Epoch 2/5, Loss: 0.8095153570175171\n",
      "Epoch 3/5, Loss: 0.5706993341445923\n",
      "Epoch 4/5, Loss: 0.8168092966079712\n",
      "Epoch 5/5, Loss: 0.5329379439353943\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Definición de un modelo simple (ejemplo)\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(10, 2)  # Capa totalmente conectada (10 entradas, 2 salidas)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Inicializa el modelo\n",
    "model = SimpleModel()  # Asegúrate de que el modelo esté definido antes de usarlo\n",
    "\n",
    "# Ejemplo de datos aleatorios para el DataLoader\n",
    "# Genera 100 muestras de entrada (10 características cada una) y 100 etiquetas\n",
    "inputs = torch.randn(100, 10)  # 100 muestras, 10 características\n",
    "labels = torch.randint(0, 2, (100,))  # 100 etiquetas (0 o 1)\n",
    "\n",
    "# Definición del dataloader, criterion y optimizer (ejemplo)\n",
    "dataset = TensorDataset(inputs, labels)  # Crea un dataset a partir de los datos\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)  # Crea un DataLoader\n",
    "criterion = nn.CrossEntropyLoss()  # Función de pérdida\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Optimizador\n",
    "\n",
    "# Definición de la función de entrenamiento\n",
    "def train_model(model, dataloader, criterion, optimizer, epochs):\n",
    "    model.train()  # Establece el modelo en modo de entrenamiento\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in dataloader:  # Itera sobre el dataloader\n",
    "            optimizer.zero_grad()  # Limpia los gradientes\n",
    "            outputs = model(inputs)  # Realiza la predicción\n",
    "            loss = criterion(outputs, labels)  # Calcula la pérdida\n",
    "            loss.backward()  # Calcula los gradientes\n",
    "            optimizer.step()  # Actualiza los parámetros del modelo\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')  # Imprime la pérdida por época\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, dataloader, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8983b8-e35b-492b-8011-9fdeeb1cc71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Definición de un modelo simple (ejemplo)\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(784, 10)  # Ejemplo para un modelo de clasificación de imágenes (como MNIST)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Crear una instancia del modelo\n",
    "model = SimpleModel()  # Definimos el modelo aquí\n",
    "\n",
    "# Definición del criterio y optimizador\n",
    "criterion = nn.CrossEntropyLoss()  # Función de pérdida\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Optimizador\n",
    "\n",
    "# Asegúrate de que 'dataloader' y 'device' estén definidos antes de llamar a 'train_model'\n",
    "# Por ejemplo:\n",
    "# dataloader = ...  # Tu DataLoader aquí\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)  # Mover el modelo al dispositivo\n",
    "\n",
    "# Entrenar el modelo\n",
    "train_model(model, dataloader, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358f46a1-55b1-4227-970e-2ba10300f8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Definición de un modelo simple (ejemplo)\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(784, 10)  # Ejemplo para un modelo de clasificación de imágenes (como MNIST)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Crear una instancia del modelo\n",
    "model = SimpleModel()  # Definimos el modelo aquí\n",
    "\n",
    "# Definición del criterio y optimizador\n",
    "criterion = nn.CrossEntropyLoss()  # Función de pérdida\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Optimizador\n",
    "\n",
    "# Definición de la función de entrenamiento\n",
    "def train_model(model, dataloader, criterion, optimizer, epochs=5):\n",
    "    model.train()  # Poner el modelo en modo de entrenamiento\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in dataloader:  # Iterar sobre el DataLoader\n",
    "            optimizer.zero_grad()  # Reiniciar los gradientes\n",
    "            outputs = model(inputs)  # Hacer una predicción\n",
    "            loss = criterion(outputs, labels)  # Calcular la pérdida\n",
    "            loss.backward()  # Retropropagar la pérdida\n",
    "            optimizer.step()  # Actualizar los parámetros del modelo\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')  # Imprimir la pérdida por época\n",
    "\n",
    "# Asegúrate de que 'dataloader' y 'device' estén definidos antes de llamar a 'train_model'\n",
    "# Por ejemplo:\n",
    "# dataloader = ...  # Tu DataLoader aquí\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)  # Mover el modelo al dispositivo\n",
    "\n",
    "# Entrenar el modelo\n",
    "# train_model(model, dataloader, criterion, optimizer, epochs=5)  # Descomentar esta línea cuando 'dataloader' esté definido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdebd81-03bd-4765-8b60-9ac1578a6685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062babe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar el lienzo\n",
    "from IPython.display import display  # Importar la función display\n",
    "\n",
    "# Crear un lienzo (canvas) de ejemplo\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crear un lienzo (canvas) usando matplotlib\n",
    "fig, ax = plt.subplots()\n",
    "canvas = fig.canvas  # Definir el objeto canvas\n",
    "\n",
    "# Mostrar el lienzo\n",
    "display(canvas)  # Mostrar el lienzo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e826ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta celda realiza las siguientes operaciones:\n",
    "# - Utiliza un modelo previamente entrenado para predecir la clase de un dibujo en el lienzo.\n",
    "# - Limpia el lienzo después de realizar una predicción.\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Crear la transformación que se debe aplicar al dibujo\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                  # Convierte a tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))    # Normaliza (ajusta según las necesidades del modelo)\n",
    "])\n",
    "\n",
    "# Función para obtener la imagen desde el lienzo\n",
    "def get_drawing():\n",
    "    img = Image.fromarray(canvas.get_image_data(0, 0, 200, 200))\n",
    "    img = img.convert(\"L\")  # Convertir a escala de grises\n",
    "    img = img.resize((28, 28))  # Redimensionar a 28x28 píxeles\n",
    "    return np.array(img)  # Retorna como un array NumPy\n",
    "\n",
    "# Función para predecir usando el modelo\n",
    "def predict_drawing(model, dataset):\n",
    "    # Obtener el dibujo actual del lienzo\n",
    "    img = get_drawing()\n",
    "    \n",
    "    # Preprocesar la imagen\n",
    "    img_tensor = transform(Image.fromarray(img)).unsqueeze(0)  # Agregar dimensión batch\n",
    "    \n",
    "    # Enviar la imagen al modelo para predicción\n",
    "    model.eval()  # Establecer el modelo en modo evaluación\n",
    "    with torch.no_grad():  # Desactivar gradientes para predicción\n",
    "        output = model(img_tensor)  # Obtener las predicciones\n",
    "        pred = torch.argmax(output, dim=1).item()  # Obtener la clase predicha\n",
    "    \n",
    "    # Mapear la predicción a la etiqueta correspondiente\n",
    "    label = list(dataset.label_to_idx.keys())[list(dataset.label_to_idx.values()).index(pred)]\n",
    "    print(f\"Predicción: {label}\")\n",
    "\n",
    "# Ejemplo de uso después de dibujar algo en el lienzo:\n",
    "predict_drawing(model, dataset)\n",
    "\n",
    "#Limpiar el canvas después de la prediccion\n",
    "canvas.clear()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd5d67-c2c7-4710-a8c4-3a8d418edaee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0e85bf95c59c41f490af95997f5cc82c": {
      "model_module": "ipycanvas",
      "model_module_version": "^0.13",
      "model_name": "CanvasManagerModel",
      "state": {
       "_model_module_version": "^0.13",
       "_view_module": null,
       "_view_module_version": ""
      }
     },
     "1c43881655dc4709a2c5394315761dc8": {
      "buffers": [
       {
        "data": "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",
        "encoding": "base64",
        "path": [
         "image_data"
        ]
       }
      ],
      "model_module": "ipycanvas",
      "model_module_version": "^0.13",
      "model_name": "CanvasModel",
      "state": {
       "_canvas_manager": "IPY_MODEL_0e85bf95c59c41f490af95997f5cc82c",
       "_model_module_version": "^0.13",
       "_view_module_version": "^0.13",
       "height": 200,
       "layout": "IPY_MODEL_23aa5e585b5e46349e0ffa2d75585c1e",
       "sync_image_data": true,
       "width": 200
      }
     },
     "23aa5e585b5e46349e0ffa2d75585c1e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
